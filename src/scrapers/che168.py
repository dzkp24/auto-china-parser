import re
import json
import asyncio
from datetime import datetime
from bs4 import BeautifulSoup
from loguru import logger
from src.scrapers.base import BaseScraper
from src.services.font_decoder import FontDecoder

class Che168Scraper(BaseScraper):
    def __init__(self):
        super().__init__()
        self.decoder = FontDecoder()
        
        self.COLORS_MAP = {
            "é»‘è‰²": ("Black", "Ğ§ĞµÑ€Ğ½Ñ‹Ğ¹"), "ç™½è‰²": ("White", "Ğ‘ĞµĞ»Ñ‹Ğ¹"),
            "ç°è‰²": ("Grey", "Ğ¡ĞµÑ€Ñ‹Ğ¹"), "é“¶è‰²": ("Silver", "Ğ¡ĞµÑ€ĞµĞ±Ñ€Ğ¸ÑÑ‚Ñ‹Ğ¹"),
            "çº¢è‰²": ("Red", "ĞšÑ€Ğ°ÑĞ½Ñ‹Ğ¹"), "è“è‰²": ("Blue", "Ğ¡Ğ¸Ğ½Ğ¸Ğ¹"),
            "æ£•è‰²": ("Brown", "ĞšĞ¾Ñ€Ğ¸Ñ‡Ğ½ĞµĞ²Ñ‹Ğ¹"), "ç»¿è‰²": ("Green", "Ğ—ĞµĞ»ĞµĞ½Ñ‹Ğ¹"),
            "é»„è‰²": ("Yellow", "Ğ–ĞµĞ»Ñ‚Ñ‹Ğ¹"), "ç´«è‰²": ("Purple", "Ğ¤Ğ¸Ğ¾Ğ»ĞµÑ‚Ğ¾Ğ²Ñ‹Ğ¹"),
            "é¦™æ§Ÿè‰²": ("Champagne", "Ğ¨Ğ°Ğ¼Ğ¿Ğ°Ğ½ÑŒ"), "æ©™è‰²": ("Orange", "ĞÑ€Ğ°Ğ½Ğ¶ĞµĞ²Ñ‹Ğ¹")
        }
        
        self.FUEL_MAP = {
            "æ±½æ²¹": "petrol", "çº¯ç”µåŠ¨": "electric",
            "æ²¹ç”µæ··åˆ": "hybrid", "æ’ç”µå¼æ··åˆåŠ¨åŠ›": "phev", "æŸ´æ²¹": "diesel",
            "å¢ç¨‹å¼": "range_extender", "ç‡ƒæ–™ç±»å‹": "unknown"
        }

        self.TRANSMISSION_MAP = {
            "è‡ªåŠ¨": "automatic", "æ‰‹åŠ¨": "manual",
            "æ‰‹è‡ªä¸€ä½“": "automatic", "åŒç¦»åˆ": "robot", "æ— çº§å˜é€Ÿ": "cvt", "å›ºå®šé½¿æ¯”": "fixed"
        }

    async def _fetch_font(self, html: str) -> bytes | None:
        match = re.search(r"url\('//(k2\.autoimg\.cn/.*?\.ttf)'\)", html)
        if match:
            url = "https://" + match.group(1)
            try:
                resp = await self.session.get(url)
                return resp.content
            except Exception:
                pass
        return None

    def _clean_number(self, text: str) -> float | None:
        """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ¸Ğ· ÑÑ‚Ñ€Ğ¾ĞºĞ¸ (96kwh -> 96.0)"""
        if not text: return None
        match = re.search(r"(\d+(\.\d+)?)", text)
        return float(match.group(1)) if match else None

    async def parse_list(self, page: int):
        url = f"https://www.che168.com/china/a0_0msdgscncgpi1lto8csp{page}exx0/"
        logger.info(f"Fetching list page {page}: {url}")
        
        try:
            response = await self.session.get(url)
            html = response.text
            soup = BeautifulSoup(html, "html.parser")
            
            page_title = soup.title.string.strip() if soup.title else "NO TITLE"
            if "éªŒè¯" in page_title or "verify" in response.url:
                logger.error("ğŸ›‘ CAPTCHA DETECTED! Need proxies.")
                return []

            items = soup.find_all(attrs={"infoid": True})
            logger.info(f"âœ… Found {len(items)} items on page {page}")

            results = []
            for item in items:
                try:
                    car_id = item["infoid"]
                    link_el = item.select_one("a.carinfo") or item.find("a")
                    if not link_el or not link_el.has_attr("href"): continue
                        
                    href = link_el["href"]
                    if href.startswith("//"): full_link = "https:" + href
                    elif href.startswith("/"): full_link = "https://www.che168.com" + href
                    else: full_link = href

                    title_el = item.select_one(".card-name") or item.select_one(".car-name")
                    title = title_el.get_text(strip=True) if title_el else "No Title"

                    results.append({
                        "external_id": car_id,
                        "link": full_link,
                        "title": title,
                        "source": "che168"
                    })
                except Exception:
                    continue
            return results
        except Exception as e:
            logger.error(f"Global error in parse_list: {e}")
            return []

    async def parse_detail(self, url: str, basic_info: dict = None):
        logger.info(f"Parsing detail: {url}")
        try:
            response = await self.session.get(url)
            html = response.text
        except Exception:
            return basic_info

        font_bytes = await self._fetch_font(html)
        soup = BeautifulSoup(html, "html.parser")

        raw_attrs = {}
        all_uls = soup.select(".all-basic-content .basic-item-ul")
        
        for ul in all_uls:
            for li in ul.find_all("li", recursive=False):
                if "highlights" in li.get_text().lower() or "é…ç½®äº®ç‚¹" in li.get_text():
                    continue

                p_tag = li.select_one(".item-name")
                if p_tag:
                    key_raw = p_tag.get_text(strip=True)
                    key_clean = re.sub(r'\s+', '', key_raw)
                    
                    full_text = li.get_text(strip=True)
                    val = full_text.replace(key_raw, "", 1).strip()
                    
                    val = self.decoder.decode(font_bytes, val)
                    raw_attrs[key_clean] = val

        features = []
        options_ul = soup.select_one("#caroptionulid")
        if options_ul:
            for li in options_ul.find_all("li"):
                feature_name = li.select_one(".item-status") or li.select_one("p")
                if feature_name:
                    features.append(feature_name.get_text(strip=True))

        external_id = basic_info.get('external_id') if basic_info else url.split("/")[-1].replace(".html", "")
        
        desc_el = soup.select_one("#messageBox")
        description_text = self.decoder.decode(font_bytes, desc_el.get_text("\n", strip=True)) if desc_el else ""
        stock_match = re.search(r"è½¦è¾†ç¼–ç [ï¼š:]\s*(\d+)", description_text)
        stock_id = stock_match.group(1) if stock_match else external_id

        images = []
        for img in soup.select(".swiper-slide img"):
            src = img.get('src') or img.get('data-src') or ""
            if src.startswith("//"): images.append("https:" + src)
        images = list(set(images))

        title = soup.select_one(".car-brand-name")
        title_text = title.get_text(strip=True) if title else (basic_info.get('title') if basic_info else "Unknown")
        
        price_el = soup.select_one("#overlayPrice")
        price_raw = self.decoder.decode(font_bytes, price_el.get_text(strip=True)) if price_el else "0"
        price_val = self._clean_number(price_raw) or 0
        if "ä¸‡" in price_raw: price_val *= 10000 
        
        fuel_val = raw_attrs.get("ç‡ƒæ–™ç±»å‹") or raw_attrs.get("èƒ½æºç±»å‹") or raw_attrs.get("Fueltype") or "æ±½æ²¹"
        engine_str = raw_attrs.get("å‘åŠ¨æœº") or raw_attrs.get("engine") or ""
        
        is_electric = False
        if "çº¯ç”µåŠ¨" in fuel_val or "pure electric" in fuel_val or "electric" in engine_str:
            is_electric = True
            fuel_type = "electric"
        elif "æ··" in fuel_val or "hybrid" in fuel_val:
            fuel_type = "hybrid"
        else:
            fuel_type = "petrol"

        battery_val = raw_attrs.get("ç”µæ± å®¹é‡") or raw_attrs.get("Standardcapacity")
        battery_capacity = self._clean_number(battery_val) # kWh

        range_val = (
            raw_attrs.get("CLTCçº¯ç”µç»­èˆªé‡Œç¨‹") or 
            raw_attrs.get("NEDCçº¯ç”µç»­èˆªé‡Œç¨‹") or 
            raw_attrs.get("CLTCpureelectricrange")
        )
        electric_range = int(self._clean_number(range_val) or 0)
        
        power_match = re.search(r"(\d+)\s*(é©¬åŠ›|horsepower|hp)", engine_str)
        engine_power = float(power_match.group(1)) if power_match else None
        
        disp_str = raw_attrs.get("æ’é‡") or raw_attrs.get("displacement") or engine_str
        displacement = 0.0
        if disp_str:
            disp_match = re.search(r"(\d+(\.\d+)?)[LT]", disp_str)
            if disp_match: displacement = float(disp_match.group(1))

        reg_date = raw_attrs.get("ä¸Šç‰Œæ—¶é—´") or raw_attrs.get("Registrationtime") or ""
        year = int(self._clean_number(reg_date[:4])) if reg_date else datetime.now().year
        
        mileage_raw = raw_attrs.get("è¡¨æ˜¾é‡Œç¨‹") or raw_attrs.get("Mileagedisplayed") or "0"
        mileage_val = self._clean_number(mileage_raw) or 0

        if "ä¸‡" in mileage_raw or "million" in mileage_raw or mileage_val < 500:
            mileage_val = int(mileage_val * 10000)
        else:
            mileage_val = int(mileage_val)

        # Ğ¡Ğ±Ğ¾Ñ€ĞºĞ°
        laravel_data = {
            "external_id": external_id,
            "stock_id": stock_id,
            "title": title_text,
            "description": description_text,
            "price": price_val,
            "images": images,
            "status": "active",
            "location": raw_attrs.get("æ‰€åœ¨åœ°") or raw_attrs.get("Location") or "China",
            "source_link": url,
            "views": 0,
            
            "color_en": self.COLORS_MAP.get(raw_attrs.get("è½¦èº«é¢œè‰²"), ("Other", "Ğ”Ñ€ÑƒĞ³Ğ¾Ğ¹"))[0],
            "color_ru": self.COLORS_MAP.get(raw_attrs.get("è½¦èº«é¢œè‰²"), ("Other", "Ğ”Ñ€ÑƒĞ³Ğ¾Ğ¹"))[1],
            "fuel_type": fuel_type,
            "drive_type": raw_attrs.get("é©±åŠ¨æ–¹å¼") or raw_attrs.get("drivingmethod") or "FWD",
            "body_type": raw_attrs.get("è½¦è¾†çº§åˆ«") or raw_attrs.get("VehicleClass") or "SUV",
            "transmission_type": "automatic", 
            "year": year,
            "mileage": mileage_val,
            
            "is_electric": is_electric,
            "engine_power": engine_power,
            "displacement": displacement,
            "battery_capacity": battery_capacity,
            "electric_range": electric_range if electric_range > 0 else None,
            "fast_charge_time": self._clean_number(raw_attrs.get("æ ‡å‡†å¿«å……") or raw_attrs.get("Standardfastcharging")),
            "slow_charge_time": None,
            "accelerate": None,
            
            "raw_attributes": json.dumps(raw_attrs, ensure_ascii=False),
            "features": json.dumps(features, ensure_ascii=False), 
            "parsed_success": True
        }

        return laravel_data